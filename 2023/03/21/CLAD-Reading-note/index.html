<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>CLAD Reading note | Wandering's Blog</title><meta name="author" content="Wandering"><meta name="copyright" content="Wandering"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Abstract 原文：CLAD :A realistic Continual Learning benchmark for Autonomous Driving, generated by HuaWei Noah’s Ark Lab   	      	    CLAD：新的自动驾驶持续学习基准，侧重于物体分类和物体检测问题（object classsification and object">
<meta property="og:type" content="article">
<meta property="og:title" content="CLAD Reading note">
<meta property="og:url" content="https://wanderer7-sk.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/index.html">
<meta property="og:site_name" content="Wandering&#39;s Blog">
<meta property="og:description" content="Abstract 原文：CLAD :A realistic Continual Learning benchmark for Autonomous Driving, generated by HuaWei Noah’s Ark Lab   	      	    CLAD：新的自动驾驶持续学习基准，侧重于物体分类和物体检测问题（object classsification and object">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://file.crazywong.com/gh/jerryc127/CDN@latest/cover/default_bg.png">
<meta property="article:published_time" content="2023-03-21T00:15:34.000Z">
<meta property="article:modified_time" content="2023-03-22T06:46:35.306Z">
<meta property="article:author" content="Wandering">
<meta property="article:tag" content="hexo,html,css,javaScript,Nodejs,Vue">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://file.crazywong.com/gh/jerryc127/CDN@latest/cover/default_bg.png"><link rel="shortcut icon" href="/wandering.github.io/img/favicon.png"><link rel="canonical" href="https://wanderer7-sk.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/wandering.github.io/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/wandering.github.io/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CLAD Reading note',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-22 14:46:35'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/wandering.github.io/atom.xml" title="Wandering's Blog" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/wandering.github.io/img/img_1.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/wandering.github.io/archives/"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/wandering.github.io/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/wandering.github.io/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/wandering.github.io/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/wandering.github.io/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/wandering.github.io/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/wandering.github.io/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/wandering.github.io/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/wandering.github.io/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/wandering.github.io/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/wandering.github.io/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://file.crazywong.com/gh/jerryc127/CDN@latest/cover/default_bg.png')"><nav id="nav"><span id="blog-info"><a href="/wandering.github.io/" title="Wandering's Blog"><img class="site-icon" src="/wandering.github.io/img/img_1.jpg"/><span class="site-name">Wandering's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/wandering.github.io/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/wandering.github.io/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/wandering.github.io/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/wandering.github.io/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/wandering.github.io/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/wandering.github.io/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/wandering.github.io/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/wandering.github.io/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CLAD Reading note</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-21T00:15:34.000Z" title="发表于 2023-03-21 08:15:34">2023-03-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-03-22T06:46:35.306Z" title="更新于 2023-03-22 14:46:35">2023-03-22</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CLAD Reading note"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2><span id="abstract"> Abstract</span></h2>
<p>原文：CLAD :A realistic Continual Learning benchmark for Autonomous Driving, generated by HuaWei Noah’s Ark Lab</p>


	<div class="row">
    <embed src="/PDF/document.pdf" width="100%" height="550" type="application/pdf">
	</div>



<p>CLAD：新的自动驾驶持续学习基准，侧重于物体分类和物体检测问题（object classsification and object detection）</p>
<p>数据集：SODA10M</p>
<p>CLAD-C： 在线分类基准，通过一个时间顺序的数据流实现，提出了类和域增量挑战（class and domain incremental）</p>
<p>CLAD-D： 域增量连续对象检测基准</p>
<h2><span id="introduction"> Introduction</span></h2>
<p>对于一个自动驾驶机器学习系统，知道一个模型将如何、在何处使用，以及它将如何失败，几乎是一项不可能的任务。虽然避免所有可能的失败是不可能的，但降低将新知识纳入系统的成本是一个更可行的目标。对于机器学习的数据集，是在一个环境（context）中收集的，这个环境最终决定了机器学习过程中包含完整集合中的哪些对象</p>
<p>认识到这种环境（context）很少是恒定的，持续学习（CL）研究如何使神经网络能够以尽可能低的成本从不断变化的上下文中吸收新知识。如果没有持续的学习，解决故障案例并扩展到新的领域需要从头开始重新训练和调整模型。鉴于当代模型的尺寸不断增加，这将产生巨大的能量和时间成本。一个简单而直接的想法是仅根据新数据优化模型。但是这种技术微调会导致旧数据性能快速下降。今天，这被称为灾难性遗忘，是持续学习的最大挑战：<strong>遗忘旧知识不能是将新知识纳入系统的结果</strong>。</p>
<p>随着持续学习的发展，需要越来越严格的基准和路线来可靠地评估正在取得的进展。早期的benchmarks侧重于分类问题和流行数据集的拆分，通常是所有可以的类都被人为地划分为不同的tasks（或者contexts），随后逐个task进行模型训练，并不访问过去或者未来的数据，CL算法的性能通过每个task的最终精度来评估。这些方法构成了人为的挑战，人为（随机）选择的分布变化不能保证与真实世界的context保持一致，而且图像分类的数据集通常被设计和简化为在foreground中只有一个object。</p>
<p>本文描述了新的CLAD（自动驾驶持续学习基准）的设计与想法。其中CLAD-C上测试了一个关于沿时间维度自然发生的context变化的连续分类模型，ClAD-D关注更显示的连续对象检测问题。本文引入这两种设置，总结了关于最有前途的提交想法的进一步细节和实验，讨论了未来的研究方向，以改进基准，以及总体上的持续学习</p>
<p>本文的主要贡献：</p>
<ol>
<li>回顾了当前CL-benchmarks及其相互关系和它们中缺点的审查。</li>
<li>引入了两个新的CL-benchmarks，以更接近现实问题中遇到的CL场景</li>
<li>回顾SSLAD ICCV 关于proposed benchmarks的最佳表现方法，强调了改善当前持续学习状态的具体方法。</li>
</ol>
<h2><span id="a-continual-learning-framework"> A Continual Learning Framework</span></h2>
<p>本节文章回顾了已经提出的tasks 和 datasets，重点介绍作者认为的以计算机视觉为重点的任务与数据集。</p>
<h3><span id="21-continual-tasks"> 2.1、Continual Tasks</span></h3>
<p>Class-incremental learning：类增量学习是指，不同时刻到达的数据属于同一任务的不同类别，类增量学习要求模型进行单头输出，并且能够增加输出的类别。相比于任务增量学习，类别增量学习前后数据之间的互相干扰更大，难度更高.（x的类分布增加，y标签的分布也增加）</p>
<p>Domain-incremental learning：域增量学习是指，不同时刻到达的数据属于同一任务的相同类别，但是数据分批次到达，且领域（domain）发生了变化，不同批次的数据不再符合静态同分布假设。在这个意义上，域增量学习与在线学习有相同之处，但增量学习突出强调了模型的抗遗忘能力.</p>
<p>task-incremental learning：任务增量学习是指不同时刻到达的数据分属于不同的任务，同一任务的数据能够一个批次全部到达。由此导致的一个特点是，在一个任务中，我们可以获得当前任务的全量数据，从而可以遵循当前神经网络的学习范式，在独立同分布的假设下训练模型。同时，既然不同任务的输出互相独立，模型可以通过多头网络的方式实现。这也意味着，在预测阶段，我们需要根据需要指定输出头。</p>
<h3><span id="22-contemporary-cl-for-computer-vision"> 2.2、Contemporary CL for Computer Vision</span></h3>
<p>统计分析了2017-2022年的一些papers，对他们的工作有了一个初步的统计结论</p>
<p><img src="/wandering.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/image-1.png" alt="image-1"></p>
<p>其中，90%使用非连续数据集，并以离散的间隔随机改变P(X)，这样每个类在单个上下文中只有非零概率(严格的类增量)。8.5%改变了P(X)而不影响P(Y)(严格的域增量)，只有1.5%包含更渐进的上下文切换。虽然这些基准测试中的随机和离散上下文开关只是cl -问题空间的一小部分，但它们目前被用于评估几乎所有新的cl -算法的质量。</p>
<h3><span id="23-towards-more-realistic-benchmarks"> 2.3、Towards more realistic benchmarks</span></h3>
<ul>
<li>尽管离散和随机分布移位是研究持续学习的一个有趣的工具，但如前所述，它们不一定代表可以使用持续学习系统的不断变化的环境。</li>
<li>实际上在严格的类增量和域增量学习之间存在一个完整的环境变化连续体</li>
<li>CORe50，iCub， Toys-200：现实的CL基准应该能够访问同一对象的多个视图，这与P（x）更逐渐变化的背景相一致</li>
<li>部分人批评CL基准中缺乏类重复，并认为这是人为地增加类增量学习的难度，不符合现实世界的场景。</li>
<li>Wanderlust、Clear、CLOC利用一天的时间作为环境变量，数据和标签分布都会发生逐渐且非随机的变化，以接近真实世界的设置</li>
</ul>
<p>真实世界基准应该是什么样的呢？文章给出了不同工作的不同见解。</p>
<h3><span id="24-evaluationn-of-continual-learning"> 2.4、Evaluationn of Continual Learning</span></h3>
<p>CL方法通常使用训练结束时每个任务的平均准确度和平均向后转移（BWT）进行评估；一项任务在训练后和所有任务训练后的准确性之间的差异。这些指标不一定与CL的目标——将新知识纳入已经运行的系统一致。按理来说，最好的算法是具有最高最终精度的算法，然而我们注意到BWT度量也能够受益于训练期间的低精度（即，这种效果改善了度量）。相反，文章认为最好的CL算法是具有高精度的算法，其可以通过包含新数据来改进，而不会突然地性能下降。理想情况下，这将在训练期间被连续测量，并且用精度曲线下的面积作为度量。实际上，这具有很高的计算成本，并且在精心选择的离散间隔进行测试是一种合理的近似。</p>
<h2><span id="continual-learning-benchmark-for-autonomous-driving"> Continual Learning Benchmark for Autonomous Driving</span></h2>
<p>应用SODA10M数据集描述作者的continual learning benchmark。</p>
<h3><span id="31-soda10m-dataset"> 3.1、SODA10M Dataset</span></h3>
<p>该数据集包含10M个未标记图像和20K个标记图像，图像数据由行车记录仪记录的片段组成，这些片段是从中国四个城市行驶的车辆中获取的，每隔10秒记录一次图像。按时间顺序排列图像在很大程度上需要一辆汽车探索城市及其周边地区的视觉镜头。图像标签集有6个对象类的边界框注释，并涵盖不同的“域”（城市、天气状况、一天中的时间和道路类型），随后将未标记的图像用于未来的工作，并将标记的数据集部分专门用于我们的基准挑战。</p>
<h3><span id="32-challenge-subtracks"> 3.2、Challenge  Subtracks</span></h3>
<p>目前存在着两个主轴，沿着这两个主轴不断学习现实世界任务的现实性增加：第一，问题的表述本身，第二，更现实的语境转移。 理想情况下，本文将这些方面组合成一个单一的综合基准。 然而，鉴于这个连续的目标检测仍处于起步阶段，本文认为制作两个独立的基准更有用； 沿着每一个轴，但保留未来合并的潜力。 在CLAD-C基准中，本文首先关注使用时间戳作为上下文变量的自然发生的分布移动，而在CLAD-D基准中，本文关注连续的对象检测。</p>
<h3><span id="33-clad-conline-continual-classification"> 3.3、CLAD-C：Online Continual Classification</span></h3>
<p>Setup：文章的第一个设计原则涵盖了在线设置，其中没有明确的任务边界。利用SODA10M中图像的时间元数据，我们可以构建一个跨越三天三夜的在线数据流。这条流以不同的频率显示域的变化:从高速公路到城市街道的变化是有规律的，几乎是突然的，而从白天到晚上的变化则不那么频繁，更渐进。最后，天气可能会不可预测地迅速变化。逐渐改变数据分布会导致图像流中不同类别出现的频率发生逐渐但剧烈的变化(例如，在夜间和高速公路上行人明显很少)。像CORe50这样的基准测试的多视图论证在这里也适用。因为这些图像的间隔是10秒，所以之前图像和场景中的物体很有可能出现在当前图像中，很可能是从不同的观看角度。正如Cossu等人所认为的，过去类别的重复构成了一个现实的环境和场景，这反映在可用的时间流中。然而，除了汽车对象之外，在某些时期，所有对象类都会从流中消失。在这样的时刻，我们推测灾难性的遗忘可以通过使用适当的CL-strategies来预防。</p>
<p>为了创建对象实例流，我们从按时间顺序排列的图像开始，并从它们的边界框中剪切目标对象。然后我们将它们的纵横比更改为1:1(沿最短轴填充)，添加额外填充，并重新缩放到32×32。过大和太小(&lt; 1024像素)的对象被删除。</p>
<p>Setup：</p>
<ul>
<li>利用SODA10M中图像的时间元数据，我们可以构建一个跨越三天三夜的在线数据流，这条流以不同的频率显示域的变化</li>
<li>逐渐改变数据分布会导致图像流中不同类别出现的频率发生逐渐但剧烈的变化</li>
<li>因为这些图像的间隔是10秒，所以之前图像和场景中的物体很有可能出现在当前图像中，很可能是从不同的观看角度。正如Cossu等人所认为的，过去类别的重复构成了一个现实的环境和场景，这反映在可用的时间流中</li>
<li>为了创建对象实例流，我们从按时间顺序排列的图像开始，并从它们的边界框中剪切目标对象。然后我们将它们的纵横比更改为1:1(沿最短轴填充)，添加额外填充，并重新缩放到32×32。过大和太小(&lt; 1024像素)的对象被删除。</li>
<li>然而，除了汽车对象之外，在某些时期，所有对象类都会从流中消失。在这样的时刻，我们推测灾难性的遗忘可以通过使用适当的CL-strategies来预防。</li>
</ul>
<p>Evaluation：AMCA（Average Mean Class Accuracy）：</p>
<p><img src="/wandering.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/image-2.png" alt="image-2"></p>
<p>Baselines：</p>
<ul>
<li>Naive finetuning：受制于灾难性的遗忘，其中类的准确性密切跟随流中存在的类分布，以及昼夜之间的变化。</li>
<li>Oversampling replay:克服大类的不平衡问题，我们允许存储1000个样本，在所有类中平均分配。在更新模型之前，每个传入的批都使用来自内存的样本进行扩展，使每个类的样本数量至少等于2b/C，其中b为批大小，C为类数量。</li>
</ul>
<p>微调和过采样基准分别达到36.8和53.5 AMCA。两个基准测试都使用ImageNet预训练的Resnet50进行训练，使用SGD和10个批次(新样本)。</p>
<p><img src="/wandering.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/image-3.png" alt="image-3"></p>
<p>fine-tuning：在实践中，由于数据集不够大，很少有人从头开始训练网络。常见的做法是使用预训练的网络（例如在ImageNet上训练的分类1000类的网络）来重新fine-tuning（也叫微调），或者当做特征提取器。</p>
<p>oversampling：指对训练集中某类样例增加采样次数以减小类别不平衡的问题</p>
<h3><span id="34-clad-dcontinual-object-detection"> 3.4、CLAD-D：Continual Object Detection</span></h3>
<p>setup：考虑到目标检测对大量数据的依赖，以及SODA10M中标记数据的有限数量，我们为自动驾驶设计了一个域增量基准测试，该基准测试补充了现有的替代CL基准测试。我们的初步实验确定了高速公路、夜晚和雨天构成的域会对晴朗天气、白天城市中心域造成干扰，而白天城市中心域拥有最多的可用数据。我们将标记数据分为四种情况:(1)晴朗的天气，白天在城市街道上，(2)晴朗的天气，白天在高速公路上，(3)晚上，(4)白天下雨。我们强调，模型在测试时不知道图像属于哪个域或任务，但我们确实允许每个任务有多个epoch，使问题更可行。</p>
<p><img src="/wandering.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/image-20221101112053278.png" alt="image-20221101112053278"></p>
<p>evaluation：我们在训练结束时使用每个任务的平均mAP。另一种选择是在每个任务之后测量准确性，并在所有测试时间中取一个平均值，就像CLAD-C基准测试一样。我们选择在这里不这样做，为了(1)保持与当前的COD评估标准一致(2)赋予每个任务同等的权重。我们报告的mAP为IOU的0.5级别，紧随VOC基准。</p>
<p>Baselines：本文通过使用ImageNet Resnet50骨干网对FasterRCNN网络上的每个任务进行微调，测试了CLAD-D基准测试的难度。使用SGD更新模型，学习速率为0.01，动量为0.9，批量大小为8。在第8和11个epoch，学习率衰减了10倍。最终任务平均mAP为59.8。图5显示了训练每个任务后的结果，暴露了学习后的任务遗忘。尽管遗忘不像在增量分类设置中通常观察到的那样是灾难性的，但可以观察到，在这种设置中有效利用所有数据是一个挑战</p>
<p><img src="/wandering.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/image-20221101111709775.png" alt="image-20221101111709775"></p>
<h2><span id="iccv-sslad-challenge-results"> ICCV SSLAD challenge results</span></h2>
<p>CLAD-C和CLAD-D都是2021年10月ICCV SSLAD讲习班的一部分，分别有49和55个团队参加。在本节中，我们将总结每个基准测试的前三名参与者的技术和想法。</p>
<h3><span id="41-clad-c"> 4.1、CLAD-C</span></h3>
<p>选择了ICCV SSLAD challenge前三名的模型进行定性分析。</p>
<p>section：</p>
<p><img src="/wandering.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/image-20221031195013213.png" alt="image-20221031195013213"></p>
<p>在挑战过程中，施加了一些限制:模型大小不能超过ResNet50参数的105%，只允许在Imagenet上进行预训练，批次大小不能超过10个新样本，任何类型的样本内存限制在1000个样本。</p>
<p>Architectures：C1和C2都使用标准Resnet50，而C3使用Resnet50- d。这是在[31]中引入的，改进了ImageNet Top-1分类约1%，而不添加更多的参数。C2还测试了DenseNet169和EffecentNetV2，但在这些网络上报告的结果较差，但两者在CIFAR10(具有相同的图像大小)上的非顺序设置中表现更好。所有模型在Imagenet上进行预训练。</p>
<p>Optimizers: C1和C3采用随机梯度下降法(SGD)，学习率为0.01。C2使用Adam[34]，学习速率为0.0002。C1不使用动量、权值衰减或学习率调度。C2和C3没有提到权值衰减或动量，而是使用多步学习率调度器。</p>
<p>Data Augmentations:这三种都是水平翻转。C1将升级到224 × 224，这是原始Imagenet的大小。他们报告说，这对最终结果有很大的影响，尽管这样做没有添加任何信息。他们假设这是由于imagenet预先训练的Resnet的卷积滤波器被校准到这个尺寸。C2增加了透视变换和随机擦除，C3增加了随机旋转和颜色抖动。C2也测试了mixup，但提到这没有帮助。最初的mixup论文只报告了90时代以后Resnet50的非常有限的改进，更大的改进用于更大的网络和更多的迭代。</p>
<p>Replay：所有三个获奖作品都使用了某种形式的回放，但在样本存储和使用的细节上有所不同。重放是一种非常有效和高效的持续学习技巧[36]，但也是唯一在挑战规则中明确提到(和限制)的方法。C1在其内存中每个类保留100个样本，每个类使用储层抽样[37]选择样本。C2对输入流使用过采样，并手动设置权重。这近似于储层采样，但样本进入/离开内存的概率是固定的，而储层采样的概率是根据每一类样本的数量动态更新的。C3使用了彩虹记忆[38]的想法。他们计算新批次中每个样本的熵，然后存储5个熵最高的样本。如果内存已满，则计算所有样本在各种增广下的不确定度。然后去除50%最确定的样本。这与[38]不同，在[38]中，样本存储在所有级别的不确定性中。这个想法是作为一个代理来选择不同的样本。C1、C2、C3每批分别使用5+5、4+6、10+6个新老样品。</p>
<p>Other Continual Learning techniques：除了前面提到的技术，前三名的提交还使用了其他持续学习的方法，在这里简要解释一下。C1使用CWR (Copy Weight with Reinit)[39]，它在每个任务之后存储头的权重，并使用随机初始化的权重重新启动。在每项任务完成后，使用指数移动平均将新旧权重合并。这在技术上需要任务边界，这并不意味着要在挑战中使用。然而，人们也可以在训练时使用任意间隔或检测任务边界，然后应用该技术。C2使用ce损耗的标签平滑版本，这被假设为创建更好的结构化特征空间[40]。他们还测试了CWR[39]和LWF (Learning Without forget)[41]，但报告使用这两种方法的效果更差(而C1确实提到CWR在他们的设置中很重要)。C3将培训分为两部分。第一部分学习度量空间，使用无监督和有监督对比损失[42]。</p>
<p>在这个空间的顶部，使用焦损失[43]训练分类头，这通常用于密集目标检测，以更容易地学习困难的类(类的样本很少)。除了焦点损失外，他们还在记忆样本的过去和当前预测logit上使用蒸馏损失，就像C2中的标签平滑一样，温度缩放。</p>
<h3><span id="42-clad-d"> 4.2、CLAD-D</span></h3>
<p>在CLAD-C中，所使用的体系结构的差异相对较小，而它们的方法差异更大。相比之下，D1使用的架构与D2和D3截然不同，而D1和D2的方法只在重要的细节上有所不同。</p>
<p><img src="/wandering.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/image-20221031201847322.png" alt="image-20221031201847322"></p>
<p>Architectures：D2和D3使用FasterRCNN[44]模型的默认 torchivision implementation，带有Resnet50特征金字塔主干，在Microsoft COCO上预先训练。D1将region proposal network改为Cascade R-CNN，其中有在多个IOU级别上训练的回归块。对于Resnet101主干网，这只提供了有限的改进。D1随后将卷积主干换成Swin transformer，这使他们的结果增加了超过15个mAP点，几乎完全缓解了遗忘(从Resnet101的14.3 mAP点到Swin transformer的1.7 mAP点)。基线Swin Transformer的参数数量大约是Resnet50的4倍，但是改进比中非顺序结果的预期要大，在中仅观察到6个mAP点的增加(在Microsoft COCO上)。</p>
<p>Optimization and augmentation：D1先在ImageNet1K上训练骨干，然后使用多步学习率调度器对挑战数据进行50个周期的训练。D2和D3使用torchvision提供的骨干，这些骨干是在Microsoft COCO上预先训练的。他们也使用多步骤调度程序（multistep schedulers），但在每个任务完成后重新使用一个循环调度（cyclic schedule）。</p>
<p>Distillation：D1和D2都使用额外的蒸馏损失将知识从一个接受过去任务训练的教师网络转移到接受新任务训练的学生网络。D2只提取网络的输出，如Shmelkov et al。D1与FasterILOD相似，使用了骨干和RPN输出上的蒸馏损失。两者都使用重放的图像进行蒸馏，而最初的Faster - ILOD依赖于新图像中未标记的旧样品的存在。</p>
<p>Replay：D1存储250张图片，用来提取老师的主干和RPN。他们没有提到他们是如何选择存储哪些样本的。D2为每个任务存储行人、自行车和三轮车最多的图像。他们没有具体说明如何使用重放。D3对2个新样本重放2个旧样本，随机存储图像。他们还提到了平衡抽样的测试，他们存储了最多三轮车的图像，但这导致了更糟糕的结果。</p>
<p>other：在D2中，网络的输出是温度缩放的，这导致不太自信的预测。</p>
<p>根据作者的说法，这导致了更好的校准和更高的mAP。</p>
<h2><span id="discussion"> Discussion</span></h2>
<ul>
<li>工作持续学习解决方案的一个重要特征是它可以从图像中提取的高级特征的通用性。简单地优化一个模型来对可用的任务数据进行分类，就可以使模型走到一个捷径解决方案，这样的解决方案只了解作为当前context一部分的实例之间的一个可能没有意义的差异。这些差异可能不足以区分当前实例与未来对象。</li>
<li>从一个实例中学习尽可能多的高级概念，有助于学习新的实例，因为模型已经学习了关于过去特征的概念，这些概念将它们与新对象区分开来。如果第一个任务是学习对柠檬和酸橙进行分类，提取这些水果的颜色可能就足够了。然后，如果下一个任务包括香蕉，模型必须了解柠檬和香蕉的形状来区分它们。这需要访问不符合cl -设置的过去数据。</li>
<li>在CLAD-C中，所有前三名的提交都是从一个Imagenet预训练模型开始的，该模型由于更大的稳定性和更好的初始特征，已被证明可以减少cl -系统中的遗忘。尽管它们有帮助，C1表明盲目使用预先训练的模型可能是次优的。尽管预先训练的卷积滤波器在相当大的窗口上是尺度不变的，但对于低于100像素的对象，其性能会迅速下降。因此，将CLAD-C的32 * 32对象升级到ImageNet的平均224 * 224对象是有用的，不是因为它增加了信息，而是因为模型适应这些大小(99%的ImageNet边界框大于100 * 100像素)。</li>
<li>具有良好的一般特征的影响可能最显著地表现在D1对CLAD-D的影响上，仅仅通过使用基于transformer的主干，他们就展示了令人印象深刻的改进。从本质上讲，vision transformers不仅优于基于卷积的网络，而且在经验上对不断变化的输入分布和异常值更稳健，对高频扰动更不敏感。transforms在持续学习中的潜力最近已在几项研究中得到验证，但收敛速度慢以及需要大量(预)训练数据构成了严重的挑战。</li>
<li>除了建立在预先训练的模型和更好的架构之上，cl -系统还应<strong>尽可能多地从可用数据中学习</strong>，这是当代解决方案尚未达到的极限。C3最明确地解决了这一挑战，直接优化以获得良好的特征嵌入，在此基础上训练分类器，这与其他使用对比损失构建良好表示的工作相似。通过这种方法学习到的特征已经被证明更健壮，结构更好。使用<strong>标签平滑损失</strong>，如C2和C3，在这方面也有帮助。标签平滑创造了一个更好的条件特征空间:“标签平滑鼓励倒数第二层的激活接近正确类的模板，与错误类的模板同样距离”。最后，我们注意到，所有前三名参与者都使用数据增强，可以减少快捷方式的数量，从而获得更好的表示。</li>
</ul>
<p>最后，我们想指出CLAD-C中的rehearsal和CLAD-D中的蒸馏的盛行。在连续分类中，Rehearsal一直是主要的方法，产生了许多变体，但对于哪些样本在CL中是最好的，以及它们究竟应该如何使用，还没有明确的答案。GDUMP甚至表明，该模型有可能只是通过从内存中提取所需的所有信息来重新学习对旧类进行分类。在检测中，所有方法都依赖于新任务训练过程中模型的蒸馏。这可能是受到SOTA方法的影响。</p>
<h2><span id="conclusion"> Conclusion</span></h2>
<p>在这项工作中，我们首先评估持续学习中目前使用的基准，以及它们如何与最可能应用持续学习的现实场景相关联。我们设计了两个提高cl -benchmark真实感的基准，使用更少的随机和更渐进的上下文转移，并从分类转移到目标检测。这两个赛道都是ICCV ’ 21的一个挑战的一部分，其中前三名参与者为我们提供了关于现实CL应用的挑战和可能的解决方案的有用见解。最后，我们讨论了CL研究的未来方向，包括从一开始就构建更好的特征表示，更好地理解CL最重要的技术——rehearsal和distillation，以启发未来的改进。我们相信这将为今后的工作提供有前途的方向。</p>
<h2><span id="appendix"> Appendix</span></h2>
<h3><span id="a1-context-as-a-framework-for-cl"> A.1. Context as a framework for CL</span></h3>
<p>class incremental learn	ing:每个context只对于特定的某些类有非零概率，并且每个类只在单个context中被观察到。</p>
<p>domain incremental learning：在每个context中以相同的频率观察所有类，但它们的外观会发生变化（旋转等）。</p>
<p>CLAD-C：与人工设计的context相反，可以使用真实世界的context。例如，在CLAD-C中，通过按时间顺序“观察”可用数据，context取决于照片拍摄的地点、一天中的时间和天气。这些变量对感兴趣对象的外观及出现频率有一定影响。</p>
<h3><span id="a2-cl-benchmarks-and-their-contexts"> A.2. CL-benchmarks and their contexts</span></h3>
<h3><span id="b1-split-details"> B.1、Split Details</span></h3>
<h3><span id="b2domain-gaps"> B.2/Domain Gaps</span></h3>
<h2><span id="extra3a_1-clad-c"> Extra：3A_1 CLAD-C</span></h2>
<h3><span id="1-competition-requirement"> 1、Competition Requirement</span></h3>
<p>3A跑道比赛的重点是持续的物体识别。数据集(见第2.1节)由6个类组成。样本以流的方式到达模型，保持原始数据的时间一致性。样本一次最多要处理10个样本，模型需要随时可供评估，在训练和测试之间不需要任何额外的计算。此外，数据必须只看到一次，因此不允许在同一经验上增加时间，所以一旦一组10个样本被模型处理，相同的样本就不能进一步利用(除非有有限的重放内存)。所需额外经费如下:</p>
<p><img src="/wandering.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/image-20221106201436639.png" alt="image-20221106201436639"></p>
<h4><span id="11-soda10m-dataset"> 1.1、Soda10M Dataset</span></h4>
<p>本次竞赛使用的数据集是Soda10M数据集[2]，这是一个为自动驾驶中的自我监督学习和领域适应而收集的大规模数据集。原始帧每10秒在32个不同的城市中收集一次，在不同的天气条件下，从这些帧中裁剪出几个边界框，用作比赛的输入。在我们看来，在数据集的具体挑战中，与竞争相关的主要问题，即可以极大地影响基于持续学习的分类器性能的因素，有以下几点:</p>
<ul>
<li>Occlusions：我们注意到，在补丁中描绘的大量对象都被遮挡了，甚至被一个属于Soda10M数据集中的类的对象遮挡了(例如，几辆公共汽车被汽车遮挡);因此，这些遮挡很容易骗过分类器的预测。</li>
<li>Image resolution：放置在远离采集设备的背景中的物体，一旦缩放到竞赛的作物大小(64 × 64)，可能会以非常低的分辨率在视觉上出现。</li>
<li>Bad quality images：在夜间和恶劣天气条件下拍摄的图像深受光线差和对比度低的影响。</li>
</ul>
<h3><span id="2-model-and-hyperparameters"> 2、Model and Hyperparameters</span></h3>
<p>我们采用ResNet-50[3]神经网络作为分类模型。最后一个完全连接的层被替换以适应竞争数据集，在最终的神经元中从1000 (Imagenet上的类的数量)传递到7(竞争中的类的数量加上一个空的)。</p>
<p>我们添加偏差以保持体系结构尽可能与原始网络相似。我们利用ImageNet-1000数据集[1]上的预训练模型。重量已经从official torchvision website下载。在ImageNet上报道的模型top-1精度为76.13%。我们使用随机梯度下降(SGD)优化器，其学习率为0.01，动量和权值衰减设置为0。作为损失函数，我们采用标准形式的交叉熵(CE)损失，可表示为:</p>
<p><img src="/wandering.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/image-20221106203150937.png" alt="image-20221106203150937"></p>
<h3><span id="3-training-procedure"> 3、Training procedure</span></h3>
<p>首先在一个张量(b, c, w, h)中转换输入批，其中b = 10(批大小)，c = 3 (RGB图像通道)，w = h = 64(图像尺寸，然后裁剪为平方)。然后，通过最近邻插值调整张量的宽度和高度，从64 × 64到224 × 224，以类似于模型预先训练的ImageNet数据集的原始图像大小。尽管这一操作可能会降低补丁的外观(输入补丁的原始大小约为最终大小的1/12)，我们注意到模型的卷积核在调整大小的图像中响应更好。这可以解释为ImageNet包含的类(如卡车、汽车、自行车等)与Soda10M数据集中的类类似，因此卷积滤波器已经过调优，以从这些图像中提取强大的特征。相同大小的图像包含相同大小(以像素为单位)的对象，因此，如果保留原始大小，则认为预先训练的过滤器反应更好是正常的。</p>
<p>然后，应用“动态”数据增强技术，以增加输入张量的变化。由于基准测试的特性，由于相同对象的许多相似图像一起提供给网络，因此输入的多样性是有限的。The motivation is the streaming natyre of the frames from which input patches are cropped（即时间顺序被保留，原始帧以低帧率获得），因此，在将张量传递给模型之前，进行水平翻转，并将原始和翻转后的版本都输入到模型中。</p>
<p>最后，只有在第一次体验期间，生成的批数据才被放入临时内存(大小为10)，并通过模型两次。在每前进一步后，计算损失和梯度，然后应用优化程序。这种操作的动机是观察到，在第一次经验中，模型的学习(特别是考虑到样本很少的类)可以通过看到更多的(甚至相同的)样本来提高。它试图模仿传统的机器学习训练过程，在这个过程中，相同的图像被多次输入到网络中。</p>
<h3><span id="4-classification-head-protection"> 4、Classification Head Protection</span></h3>
<p>神经网络中灾难性遗忘的主要原因之一是所谓的“孤立学习”问题。当每个经验中只有有限数量的类出现时，或者当一些类的代表不足时，即它们的样本数量相对于训练数据中的其他类非常少，导致这些类被遗忘时，这个问题就会出现。遗忘主要发生在分类头，即所采用的神经网络的最后一层(通常是全连接层)。</p>
<p>在我们的实验中，我们在Soda10M数据集上观察到同样的效果，可能是由于某些类别的存在非常有限(例如三轮车)，甚至完全没有(例如第二种体验只呈现了汽车、卡车和有轨电车)。我们使用[4]中提出的CWR算法来解决这个问题，该算法是作为从顺序批中持续学习的基线技术提出的。</p>
<p>CWR为分类层保持两组权重，即统一权重(cw)和临时权重(tw):</p>
<p>cw：包含在整合阶段中使用的来自以前经验的权重。在这个阶段，cw权值与当前经验权值tw合并</p>
<p>tw：包含用于在当前经验中训练模型的权重。权重在体验开始时初始化为0，只有当前体验类的权重从cw加载。</p>
<p>（与原始论文不同的是，作者没有像[5]中提出的那样冻结特征提取器的权重）</p>
<h3><span id="5-replay-memory"> 5、Replay Memory</span></h3>
<p>重播被认为是对比灾难性遗忘问题最有效的方法之一，特别是在复杂的持续学习场景中。因此，我们决定在我们的实现中采用此范式，同时采用CWR。</p>
<p>作者创建了6个不同的内存缓冲区，每个类一个。每个缓冲区在大小上都有限制:在我们的最终实现中，我们将所有类的这个限制设置为100，导致最终的样本内存大小为600。我们观察到，在每个类中包含更多的样本，或者减少被记忆的类的数量(只在内存中放入一些类)，都不会产生任何特别的好处。这可能是由于以下原因:</p>
<p>I)训练集中可使用的三轮车总数为82辆，低于固定的缓冲区大小;</p>
<p>ii)对于某些类(如汽车)，限制重放样本的数量是很重要的，因为它们代表了绝大多数输入样本。</p>
<p>增加类缓冲区大小往往会产生负面影响，因为三轮车的数量受到训练数据的限制(不超过82)，而其他类在第一次体验结束时完全占用了它们的缓冲区，使回放内存更加不平衡。以上两点的结合将创造出一个平衡的内存类，因为从第二次体验开始，内存缓冲区就已经满了(除了三轮车类)，不平衡并不明显。我们还注意到，为每个类设置不同的大小不会产生明显的改进。</p>
<p>作者将小批(大小为10)分为5个来自当前经验的样本和5个来自重放记忆的样本。使用以这种方式组成的小批次，每次体验的小批次数量翻倍。重放数据从重放存储器中随机采样，不进行替换。当内存上的所有采样完成后，再次启动采样过程</p>
<p>内存的管理方式如下:如前所述，为每个类维护一个维数为100的缓冲区，总共为600个样本。在第一次体验期间，记忆不用于训练，但来自当前体验的样本被积累在缓冲区中。如果一个特定类的缓冲区没有满，并且当前的小批中有相应类的模式，那么所有的模式都将被存储在缓冲区中。如果缓冲区已满，我们使用存储采样[6]，这保证每个样本在体验结束时都有相同的概率进入重放存储器。我们为每个类维护一个计数器，计算到目前为止看到的样本，我们更新内存如下：</p>
<p><img src="/wandering.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/image-20221106210516310.png" alt="image-20221106210516310"></p>
<p>其中d和c是小批中单个样本的数据和类，C是每个类查看样本数量的计数器，M是重放存储器，由每个类的100个元素的缓冲区组成</p>
<p>（由于我们不希望当前体验中使用的重放内存因插入来自当前体验的样本而改变，所以我们使用剩余的400个空闲内存插槽作为插入的临时缓冲区。对于每一个新的经验，我们从当前经验中插入100/i (i =当前经验的索引)样本(100来自第一个经验，50来自第二个经验，以此类推)。在第一种经验中，我们使用内存M和算法1中描述的操作。对于后续的经验，我们为每个类使用100/i维度的额外缓冲区B。按照算法1进行模式插入，但使用B代替M，缓冲区维数100/i代替100。在一个新的体验开始时，我们从M的每个类中删除100/i个元素，并从B中插入新的重放样本。注意，内存的最大分配是900个样本，因为M的维数总是600，而B的最大维数是300(在第二次体验中每个类50个样本)。）</p>
<h3><span id="6-contribution-of-the-components"> 6、Contribution of the Components</span></h3>
<p><img src="/wandering.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/image-20221106205818700.png" alt="image-20221106205818700"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://wanderer7-sk.github.io/wandering.github.io">Wandering</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://wanderer7-sk.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/">https://wanderer7-sk.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">此文章版权归Wandering所有，如有转载，请注明來自原作者</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://file.crazywong.com/gh/jerryc127/CDN@latest/cover/default_bg.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/wandering.github.io/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/wandering.github.io/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/wandering.github.io/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/wandering.github.io/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/wandering.github.io/2023/03/26/%E5%AE%A4%E5%86%85%E8%A1%8C%E4%BA%BA%E5%AE%9A%E4%BD%8D%E8%BD%A8%E8%BF%B9%E5%8F%AF%E8%A7%86%E5%8C%96%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%BC%80%E5%8F%91%E5%89%8D%E7%AB%AF%E9%83%A8%E5%88%86/" title="室内行人定位轨迹的校正方法与可视化系统的设计与开发"><img class="cover" src="https://up.36992.com/pic/e6/c5/51/e6c551e768092c8655292d89a4034a74.jpg" onerror="onerror=null;src='/wandering.github.io/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">室内行人定位轨迹的校正方法与可视化系统的设计与开发</div></div></a></div><div class="next-post pull-right"><a href="/wandering.github.io/2022/11/29/network/" title="Computer network"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Computer network</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text"> Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text"> Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text"> A Continual Learning Framework</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">3.1.</span> <span class="toc-text"> 2.1、Continual Tasks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">3.2.</span> <span class="toc-text"> 2.2、Contemporary CL for Computer Vision</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">3.3.</span> <span class="toc-text"> 2.3、Towards more realistic benchmarks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">3.4.</span> <span class="toc-text"> 2.4、Evaluationn of Continual Learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text"> Continual Learning Benchmark for Autonomous Driving</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">4.1.</span> <span class="toc-text"> 3.1、SODA10M Dataset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">4.2.</span> <span class="toc-text"> 3.2、Challenge  Subtracks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">4.3.</span> <span class="toc-text"> 3.3、CLAD-C：Online Continual Classification</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">4.4.</span> <span class="toc-text"> 3.4、CLAD-D：Continual Object Detection</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text"> ICCV SSLAD challenge results</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">5.1.</span> <span class="toc-text"> 4.1、CLAD-C</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">5.2.</span> <span class="toc-text"> 4.2、CLAD-D</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text"> Discussion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">7.</span> <span class="toc-text"> Conclusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">8.</span> <span class="toc-text"> Appendix</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">8.1.</span> <span class="toc-text"> A.1. Context as a framework for CL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">8.2.</span> <span class="toc-text"> A.2. CL-benchmarks and their contexts</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">8.3.</span> <span class="toc-text"> B.1、Split Details</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">8.4.</span> <span class="toc-text"> B.2&#x2F;Domain Gaps</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">9.</span> <span class="toc-text"> Extra：3A_1 CLAD-C</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">9.1.</span> <span class="toc-text"> 1、Competition Requirement</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link"><span class="toc-number">9.1.1.</span> <span class="toc-text"> 1.1、Soda10M Dataset</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">9.2.</span> <span class="toc-text"> 2、Model and Hyperparameters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">9.3.</span> <span class="toc-text"> 3、Training procedure</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">9.4.</span> <span class="toc-text"> 4、Classification Head Protection</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">9.5.</span> <span class="toc-text"> 5、Replay Memory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">9.6.</span> <span class="toc-text"> 6、Contribution of the Components</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://file.crazywong.com/gh/jerryc127/CDN@latest/cover/default_bg.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Wandering</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a target="_blank" rel="noopener" href="https://butterfly.js.org/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/wandering.github.io/js/utils.js"></script><script src="/wandering.github.io/js/main.js"></script><script src="/wandering.github.io/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://wanderer7-sk.github.io/wandering.github.io/2023/03/21/CLAD-Reading-note/'
    this.page.identifier = '/wandering.github.io/2023/03/21/CLAD-Reading-note/'
    this.page.title = 'CLAD Reading note'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }

  document.getElementById('darkmode').addEventListener('click', () => {
    setTimeout(() => window.disqusReset(), 200)
  })
}

if ('Valine' === 'Disqus' || !true) {
  if (true) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><div class="aplayer no-destroy" data-id="60198" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="true"> </div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>